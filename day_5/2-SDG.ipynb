{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\usvidr03\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\usvidr03\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangChain API Key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also want to set a project name to make things easier for ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"PSI - SDG - {uuid4().hex[0:8]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI's API Key!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load our data into a familiar LangChain format using the `DirectoryLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "\n",
    "path = \"bills/\"\n",
    "loader = DirectoryLoader(path, glob=\"*.pdf\", loader_cls=PyMuPDFLoader)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-nano\"))\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 0, relationships: 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.graph import KnowledgeGraph\n",
    "\n",
    "kg = KnowledgeGraph()\n",
    "kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 20, relationships: 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.graph import Node, NodeType\n",
    "\n",
    "### NOTICE: We're using a subset of the data for this example - this is to keep costs/time down.\n",
    "for doc in docs[:20]:\n",
    "    kg.nodes.append(\n",
    "        Node(\n",
    "            type=NodeType.DOCUMENT,\n",
    "            properties={\"page_content\": doc.page_content, \"document_metadata\": doc.metadata}\n",
    "        )\n",
    "    )\n",
    "kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb59359ef3454208869d41ec238357d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8aef146610b42a8b8803fcb72358de3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Node 19611763-d813-42f5-9c52-86744189cefb does not have a summary. Skipping filtering.\n",
      "Node 7d127c0a-0078-456b-8786-f2ba75a3b936 does not have a summary. Skipping filtering.\n",
      "Node 64cdf325-784d-4949-af68-3c5a22defc41 does not have a summary. Skipping filtering.\n",
      "Node 61933dd5-7b14-4c2d-8f16-184124746249 does not have a summary. Skipping filtering.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f8d7ead19f42b6bf237b15c0767d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a207c94a784c1989a9abb7dde82231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 20, relationships: 133)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.transforms import default_transforms, apply_transforms\n",
    "\n",
    "transformer_llm = generator_llm\n",
    "embedding_model = generator_embeddings\n",
    "\n",
    "default_transforms = default_transforms(documents=docs, llm=transformer_llm, embedding_model=embedding_model)\n",
    "apply_transforms(kg, default_transforms)\n",
    "kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 20, relationships: 133)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg.save(\"bills/ai_law.json\")\n",
    "bills_data_kg = KnowledgeGraph.load(\"bills/ai_law.json\")\n",
    "bills_data_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=embedding_model, knowledge_graph=bills_data_kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers import default_query_distribution, SingleHopSpecificQuerySynthesizer, MultiHopAbstractQuerySynthesizer, MultiHopSpecificQuerySynthesizer\n",
    "\n",
    "query_distribution = [\n",
    "        (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 0.5),\n",
    "        (MultiHopAbstractQuerySynthesizer(llm=generator_llm), 0.25),\n",
    "        (MultiHopSpecificQuerySynthesizer(llm=generator_llm), 0.25),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use our `TestSetGenerator` to generate our testset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61fdfc852c94422585385d8fb9f601d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52004e79890b42b68c29ff11a04b6ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc02a8bdf4f4f3da5aae5fb753af0a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the significance of CD0 Magazine in th...</td>\n",
       "      <td>[TWENTIETH CONGRESS OF THE \\nREPUBLIC OF THE P...</td>\n",
       "      <td>The context mentions CD0 Magazine as the sourc...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the concerns associated with Artifici...</td>\n",
       "      <td>[AI presents enormous opportunities for the Ph...</td>\n",
       "      <td>The concerns regarding ASI include the possibi...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the significance of Articel XIV, Secio...</td>\n",
       "      <td>[TWENTIETH CONGRESS OF THE \\nREPUBLIC OF THE P...</td>\n",
       "      <td>The context mentions Article XIV, Section 10 o...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who are the Filipinos?</td>\n",
       "      <td>[1 \\na) Promote innovation, technological adva...</td>\n",
       "      <td>The context mentions Filipinos as the group wh...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the implications of Artificial Superi...</td>\n",
       "      <td>[1\\n2\\n3\\n4\\n5\\n6\\n7\\n8 \\n9\\n10\\n11\\n12\\n13\\n1...</td>\n",
       "      <td>Artificial Superintelligence (ASI) refers to h...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How does the law's effective date relate to su...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n1 \\nendorsements, voice recordings...</td>\n",
       "      <td>The context indicates that the law shall take ...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How does the framework for responsible AI deve...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nAI presents enormous opportunities...</td>\n",
       "      <td>The context explains that the bill aims to bal...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>how do violations of safegards and skills mapp...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n1 \\ndevelopment priorities. These ...</td>\n",
       "      <td>Violations of safeguards, rules, and regulatio...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How does the AI Ethics Review Board's role in ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n1 \\ndevelopment priorities. These ...</td>\n",
       "      <td>The AI Ethics Review Board is responsible for ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How does the Philippine DICT's role in establi...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n1 \\nSec. 6. Jurisdiction of the NA...</td>\n",
       "      <td>The law assigns the DICT the role of supportin...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>how AI should be responsible in Philippines li...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n1 \\niii) Mandatory compliance trai...</td>\n",
       "      <td>The context shows that the Philippines is work...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0   What is the significance of CD0 Magazine in th...   \n",
       "1   What are the concerns associated with Artifici...   \n",
       "2   What is the significance of Articel XIV, Secio...   \n",
       "3                              Who are the Filipinos?   \n",
       "4   What are the implications of Artificial Superi...   \n",
       "5   How does the law's effective date relate to su...   \n",
       "6   How does the framework for responsible AI deve...   \n",
       "7   how do violations of safegards and skills mapp...   \n",
       "8   How does the AI Ethics Review Board's role in ...   \n",
       "9   How does the Philippine DICT's role in establi...   \n",
       "10  how AI should be responsible in Philippines li...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [TWENTIETH CONGRESS OF THE \\nREPUBLIC OF THE P...   \n",
       "1   [AI presents enormous opportunities for the Ph...   \n",
       "2   [TWENTIETH CONGRESS OF THE \\nREPUBLIC OF THE P...   \n",
       "3   [1 \\na) Promote innovation, technological adva...   \n",
       "4   [1\\n2\\n3\\n4\\n5\\n6\\n7\\n8 \\n9\\n10\\n11\\n12\\n13\\n1...   \n",
       "5   [<1-hop>\\n\\n1 \\nendorsements, voice recordings...   \n",
       "6   [<1-hop>\\n\\nAI presents enormous opportunities...   \n",
       "7   [<1-hop>\\n\\n1 \\ndevelopment priorities. These ...   \n",
       "8   [<1-hop>\\n\\n1 \\ndevelopment priorities. These ...   \n",
       "9   [<1-hop>\\n\\n1 \\nSec. 6. Jurisdiction of the NA...   \n",
       "10  [<1-hop>\\n\\n1 \\niii) Mandatory compliance trai...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   The context mentions CD0 Magazine as the sourc...   \n",
       "1   The concerns regarding ASI include the possibi...   \n",
       "2   The context mentions Article XIV, Section 10 o...   \n",
       "3   The context mentions Filipinos as the group wh...   \n",
       "4   Artificial Superintelligence (ASI) refers to h...   \n",
       "5   The context indicates that the law shall take ...   \n",
       "6   The context explains that the bill aims to bal...   \n",
       "7   Violations of safeguards, rules, and regulatio...   \n",
       "8   The AI Ethics Review Board is responsible for ...   \n",
       "9   The law assigns the DICT the role of supportin...   \n",
       "10  The context shows that the Philippines is work...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0   single_hop_specifc_query_synthesizer  \n",
       "1   single_hop_specifc_query_synthesizer  \n",
       "2   single_hop_specifc_query_synthesizer  \n",
       "3   single_hop_specifc_query_synthesizer  \n",
       "4   single_hop_specifc_query_synthesizer  \n",
       "5   multi_hop_abstract_query_synthesizer  \n",
       "6   multi_hop_abstract_query_synthesizer  \n",
       "7   multi_hop_abstract_query_synthesizer  \n",
       "8   multi_hop_specific_query_synthesizer  \n",
       "9   multi_hop_specific_query_synthesizer  \n",
       "10  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset = generator.generate(testset_size=10, query_distribution=query_distribution)\n",
    "testset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe19459c78645f2b89032b3f6e8e03c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204ebd0431304b8a8060cd5445594e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "264511711c4d4256ae7ec3e271dbd89f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "570b44e56f244b81afe8eb3d831670a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64981f8371643f8b0ed0721d2f4627a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7500e8ba7bbc44beabf75bf26b6b2317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "151bac3c4e5541b7899138b1d9a5a060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "dataset = generator.generate_with_langchain_docs(docs[:10], testset_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the significance of the REPUBLIC OF TH...</td>\n",
       "      <td>[TWENTIETH CONGRESS OF THE \\nREPUBLIC OF THE P...</td>\n",
       "      <td>The context discusses the TWENTIETH CONGRESS O...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is ASI and why is it like a big deal for ...</td>\n",
       "      <td>[AI presents enormous opportunities for the Ph...</td>\n",
       "      <td>The context mentions that the global scientifi...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does the Philippines' development of a mul...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n1 \\nk) Issue advisory opinions on ...</td>\n",
       "      <td>The Philippines' development of a multi-year A...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how do they do certification and monitoring of...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n1 \\nSec. 8. NAICSecretariat. - The...</td>\n",
       "      <td>The law states that the NAIC shall certify and...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How does the development of Artificial Superin...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nAI presents enormous opportunities...</td>\n",
       "      <td>The context highlights that AI presents signif...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How does the DOST relate to the NAIC's jurisdi...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\n1 \\nSec. 6. Jurisdiction of the NA...</td>\n",
       "      <td>The NAIC, which is attached to the Department ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  What is the significance of the REPUBLIC OF TH...   \n",
       "1  What is ASI and why is it like a big deal for ...   \n",
       "2  How does the Philippines' development of a mul...   \n",
       "3  how do they do certification and monitoring of...   \n",
       "4  How does the development of Artificial Superin...   \n",
       "5  How does the DOST relate to the NAIC's jurisdi...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [TWENTIETH CONGRESS OF THE \\nREPUBLIC OF THE P...   \n",
       "1  [AI presents enormous opportunities for the Ph...   \n",
       "2  [<1-hop>\\n\\n1 \\nk) Issue advisory opinions on ...   \n",
       "3  [<1-hop>\\n\\n1 \\nSec. 8. NAICSecretariat. - The...   \n",
       "4  [<1-hop>\\n\\nAI presents enormous opportunities...   \n",
       "5  [<1-hop>\\n\\n1 \\nSec. 6. Jurisdiction of the NA...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  The context discusses the TWENTIETH CONGRESS O...   \n",
       "1  The context mentions that the global scientifi...   \n",
       "2  The Philippines' development of a multi-year A...   \n",
       "3  The law states that the NAIC shall certify and...   \n",
       "4  The context highlights that AI presents signif...   \n",
       "5  The NAIC, which is attached to the Department ...   \n",
       "\n",
       "                       synthesizer_name  \n",
       "0  single_hop_specifc_query_synthesizer  \n",
       "1  single_hop_specifc_query_synthesizer  \n",
       "2  multi_hop_abstract_query_synthesizer  \n",
       "3  multi_hop_abstract_query_synthesizer  \n",
       "4  multi_hop_specific_query_synthesizer  \n",
       "5  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                  What is the significance of the REPUBLIC OF THE PHILIPPINES in the context of AI regulation and development?\n",
      "1                                                                                                                                                                                                                                                                                                                                                                                                                       What is ASI and why is it like a big deal for AI research and development and what are the risks and concerns about it?\n",
      "2                                                                                                                                                                                                      How does the Philippines' development of a multi-year AI Roadmap and the establishment of a National Registry of AI Systems exemplify the importance of international coordination on AI governance, and in what ways do these national initiatives align with the global frameworks and recommendations for responsible AI development?\n",
      "3    how do they do certification and monitoring of AI risks like in the law, and how does that relate to certification, and what does it mean for AI safety and risks, and how is it done in the law, and what are the rules for certifying AI risks, and how does that help with AI safety and risks, and what are the rules for certifying AI risks in the law, and how do they do it, and what are the rules for certifying AI risks, and how does that help AI safety and risks, and what does certification mean for AI risks and safety?\n",
      "4                                                                                                                                                                                                                                                                                    How does the development of Artificial Superintelligence (ASI) in the Philippines, as discussed in the context, relate to the global concerns about ASI surpassing human control and the need for responsible regulation to ensure safety and ethical use?\n",
      "5                                                                                                                                                                                                                                                                                                                                                                                                                                                       How does the DOST relate to the NAIC's jurisdiction over AI development and regulation?\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = dataset.to_pandas()\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option(\"display.colheader_justify\", \"left\")\n",
    "\n",
    "print(df['user_input'].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vSRr2MXk0P_"
   },
   "source": [
    "We'll need to provide our LangSmith API key, and set tracing to \"true\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SLtk1GtnyoY"
   },
   "source": [
    "## Task 4: LangSmith Dataset\n",
    "\n",
    "Now we can move on to creating a dataset for LangSmith!\n",
    "\n",
    "First, we'll need to create a dataset on LangSmith using the `Client`!\n",
    "\n",
    "We'll name our Dataset to make it easy to work with later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "TLgm6OjvYSsm"
   },
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "dataset_name = \"PH_AI_BILL_2025\"\n",
    "\n",
    "langsmith_dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"Philippines AI Bills 2025\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64SmXMBnzXWm"
   },
   "source": [
    "We'll iterate through the RAGAS created dataframe - and add each example to our created dataset!\n",
    "\n",
    "> NOTE: We need to conform the outputs to the expected format - which in this case is: `question` and `answer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "8nFQ6di_XnY7"
   },
   "outputs": [],
   "source": [
    "for data_row in dataset.to_pandas().iterrows():\n",
    "  client.create_example(\n",
    "      inputs={\n",
    "          \"question\": data_row[1][\"user_input\"]\n",
    "      },\n",
    "      outputs={\n",
    "          \"answer\": data_row[1][\"reference\"]\n",
    "      },\n",
    "      metadata={\n",
    "          \"context\": data_row[1][\"reference_contexts\"]\n",
    "      },\n",
    "      dataset_id=langsmith_dataset.id\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "4njbUAIsaYjB"
   },
   "outputs": [],
   "source": [
    "rag_documents = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "qWo3Ajaragv1"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 50\n",
    ")\n",
    "\n",
    "rag_documents = text_splitter.split_documents(rag_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "UwfJCzP3aqKI"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "58Ypj_NgbEsi"
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Qdrant\n",
    "\n",
    "vectorstore = Qdrant.from_documents(\n",
    "    documents=rag_documents,\n",
    "    embedding=embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"AI Bills RAG\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "SbKSjfSkbTYo"
   },
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "1sLeY1oWbVqO"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "RAG_PROMPT = \"\"\"\\\n",
    "Given a provided context and question, you must answer the question based only on context.\n",
    "\n",
    "If you cannot answer the question based on the context - you must say \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZnHDh4e1Ou5"
   },
   "source": [
    "For our LLM, we will be using TogetherAI's endpoints as well!\n",
    "\n",
    "We're going to be using Meta Llama 3.1 70B Instruct Turbo - a powerful model which should get us powerful results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "6nx-ue1XbciV"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmTL6-pc1ZGz"
   },
   "source": [
    "Finally, we can set-up our RAG LCEL chain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "TjWj0OLIbbFc"
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "    | rag_prompt | llm | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "WQ7bEweo4IIb",
    "outputId": "d161b269-f799-4920-d6ce-c202f6e783aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The penalty for using AI to create or disseminate disinformation is a fine of One Million Pesos (Php 1,000,000) to Five Million Pesos (Php 5,000,000), or imprisonment of three (3) years to ten (10) years, or both, at the discretion of the court.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\"question\" : \"How much is the penalty for spreading disinformation?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9hBh5YPrdGJ"
   },
   "source": [
    "## LangSmith Evaluation Set-up\n",
    "\n",
    "We'll use OpenAI's GPT-4.1 as our evaluation LLM for our base Evaluators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "gfwPYdIkcvpF"
   },
   "outputs": [],
   "source": [
    "eval_llm = ChatOpenAI(model=\"gpt-4.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6b8pToKH2K28"
   },
   "source": [
    "We'll be using a number of evaluators - from LangSmith provided evaluators, to a few custom evaluators!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "PXSG-_ajckp6"
   },
   "outputs": [],
   "source": [
    "from langsmith.evaluation import LangChainStringEvaluator, evaluate\n",
    "\n",
    "qa_evaluator = LangChainStringEvaluator(\"qa\", config={\"llm\" : eval_llm})\n",
    "\n",
    "labeled_helpfulness_evaluator = LangChainStringEvaluator(\n",
    "    \"labeled_criteria\",\n",
    "    config={\n",
    "        \"criteria\": {\n",
    "            \"helpfulness\": (\n",
    "                \"Is this submission helpful to the user,\"\n",
    "                \" taking into account the correct reference answer?\"\n",
    "            )\n",
    "        },\n",
    "        \"llm\" : eval_llm\n",
    "    },\n",
    "    prepare_data=lambda run, example: {\n",
    "        \"prediction\": run.outputs[\"output\"],\n",
    "        \"reference\": example.outputs[\"answer\"],\n",
    "        \"input\": example.inputs[\"question\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "empathy_evaluator = LangChainStringEvaluator(\n",
    "    \"criteria\",\n",
    "    config={\n",
    "        \"criteria\": {\n",
    "            \"empathy\": \"Is this response empathetic? Does it make the user feel like they are being heard?\",\n",
    "        },\n",
    "        \"llm\" : eval_llm\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R35sQMHVrnpl"
   },
   "source": [
    "## LangSmith Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Rag Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "122b1bd1f0e9417a8dcb57d4eebe4d2e",
      "e0c233ad01604540a6c873f4a731982d",
      "e9a01115c75b499884f7e0ef32e9e599",
      "5faba4ad609448b2b49024add4ad3b8e",
      "ef25efa751304e4699910f1fbc14345f",
      "0b44cb0f8e34446c8dde668a75d3d8ad",
      "edaac6587b2d4bd5be52b89bb097f99f",
      "7cb241365f604419af454c1c28de197a",
      "9cf586576ff44dba86ba2eb389593c61",
      "849b5c95008541d49f1ceedf0a59ac60",
      "f3665a86662746c4ac7cb0796604781d"
     ]
    },
    "id": "t7t_Uz0tdumL",
    "outputId": "d684e218-294e-4dc3-c8de-a01d397f021c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'whispered-lettuce-34' at:\n",
      "https://smith.langchain.com/o/73c7812f-fb16-4468-bb8f-115ba901532a/datasets/21fd1cce-754b-4695-81f3-4f8aefa58a02/compare?selectedSessions=9533ed6c-a6ea-4655-9f55-4163b257200b\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6cf5d680bcd4f31a3f7a29ce1fbae84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.answer</th>\n",
       "      <th>feedback.correctness</th>\n",
       "      <th>feedback.helpfulness</th>\n",
       "      <th>feedback.empathy</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does the DOST relate to the NAIC's jurisdiction over AI development and regulation?</td>\n",
       "      <td>Based on the provided context, the NAIC (National AI Commission) is an agency attached to the Department of Science and Technology (DOST). The NAIC has original and exclusive jurisdiction over all matters pertaining to AI, including its development, promotion, registration, and regulation. The Secretary of the DOST also serves as the Chairman of the NAIC.\\n\\nTherefore, the DOST relates to the NAIC's jurisdiction over AI development and regulation by being the parent department to which the NAIC is attached, and through the Secretary of the DOST who chairs the NAIC, providing leadership and oversight in these matters.</td>\n",
       "      <td>None</td>\n",
       "      <td>The NAIC, which is attached to the Department of Science and Technology (DOST), has exclusive jurisdiction over all matters pertaining to AI, including its development, promotion, registration, and regulation. The NAIC is responsible for technical support and policy alignment across government agencies involved in AI, and it can impose administrative penalties for violations, establishing a direct relationship between DOST and the NAIC's AI oversight functions.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.450819</td>\n",
       "      <td>5b0bdfed-5b90-4119-82a9-a30f2ac69a3f</td>\n",
       "      <td>1f5d6877-d2f1-4c8f-9125-e6604b9565fa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does the development of Artificial Superintelligence (ASI) in the Philippines, as discussed in the context, relate to the global concerns about ASI surpassing human control and the need for responsible regulation to ensure safety and ethical use?</td>\n",
       "      <td>The development of Artificial Superintelligence (ASI) in the Philippines is viewed within the context of global concerns about ASI surpassing human intelligence and potentially going beyond human control. The context highlights alarms raised by the global scientific and policy communities regarding these risks, which include the possibility that improperly secured or regulated ASI systems might cause harm.\\n\\nAccordingly, the Philippines recognizes the urgent need for a national framework to ensure the safe, responsible, and ethical use of AI, including ASI. This framework aims to prevent AI from being used to perpetrate crimes, abuse rights, or cause harm—whether intentional or accidental. The State bears the responsibility to regulate AI to support Filipino ingenuity and technological progress while addressing these risks.\\n\\nThus, the development of ASI in the Philippines is closely related to global concerns by emphasizing responsible regulation and oversight to manage potential risks and ensure AI technologies are aligned with ethical standards and public safety.</td>\n",
       "      <td>None</td>\n",
       "      <td>The context highlights that AI presents significant opportunities for the Philippines, including improving public services and advancing technological development. However, it also raises concerns about the rise of Artificial Superintelligence (ASI), a hypothetical AI system surpassing human intelligence and potentially beyond human control. Globally, scientific and policy communities have expressed alarms regarding the risks of ASI gaining unauthorized access to critical infrastructure and posing existential threats. The Philippines' approach, as outlined, emphasizes responsible development and regulation of AI, including ASI, to balance innovation with safety, ethics, and human oversight. This aligns with international concerns by advocating for policies that ensure ASI remains secure, transparent, and under meaningful human control to prevent misuse or unintended consequences.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.845638</td>\n",
       "      <td>cec2f7f8-bf02-482c-b1d6-484da9ee5a5f</td>\n",
       "      <td>f94fbcbd-be98-4985-9db5-d40fda209e11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how do they do certification and monitoring of AI risks like in the law, and how does that relate to certification, and what does it mean for AI safety and risks, and how is it done in the law, and what are the rules for certifying AI risks, and how does that help with AI safety and risks, and what are the rules for certifying AI risks in the law, and how do they do it, and what are the rules for certifying AI risks, and how does that help AI safety and risks, and what does certification mean for AI risks and safety?</td>\n",
       "      <td>Based on the provided context, the certification and monitoring of AI risks in the law are done through a risk-based regulatory framework implemented by the NAIC (presumably the relevant regulatory authority). This framework involves:\\n\\n1. **Risk Classification:** AI systems are classified as high-risk, moderate-risk, or low-risk based on their potential impact on safety, rights, and national interest.\\n\\n2. **Certification Requirements:** \\n   - High-risk AI systems must undergo mandatory algorithmic impact assessments, data privacy reviews, and sustainability screening before being certified for use.\\n   \\n3. **Standards Compliance:** AI systems must comply with standards for safety, transparency, accountability, explainability, and ethical compliance. This includes safeguards against discrimination, misuse, harm, or unintended consequences.\\n\\n4. **Monitoring:** The NAIC certifies and monitors AI-related risks of all AI applications, ensuring ongoing compliance.\\n\\n5. **Purpose and Impact of Certification:** Certification means that an AI system has been evaluated and approved according to established risk thresholds and standards, which helps ensure that AI applications operate safely and ethically. It mitigates risks by requiring assessments and reviews that prevent harm and uphold rights.\\n\\nOverall, the certification process under the law serves as a critical mechanism for managing AI safety and risks. It ensures that AI systems, particularly those classified as high-risk, meet stringent risk and ethical standards prior to deployment and throughout their use, thereby protecting individuals, organizations, and society from potential adverse effects.</td>\n",
       "      <td>None</td>\n",
       "      <td>The law states that the NAIC shall certify and monitor AI-related risks of all AI applications, which means they will evaluate and oversee AI systems to ensure safety and compliance. This certification process is part of a risk-based regulatory framework that classifies AI systems as high, moderate, or low risk based on their potential impact. By implementing certification and monitoring, the law aims to promote AI safety and manage risks effectively, ensuring AI systems align with ethical standards and social goals.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.589216</td>\n",
       "      <td>70734b8d-8b74-48fb-87c2-36eb0e1e0cc4</td>\n",
       "      <td>1e13d9f1-afc3-4e8c-ab5a-378af0db09c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does the Philippines' development of a multi-year AI Roadmap and the establishment of a National Registry of AI Systems exemplify the importance of international coordination on AI governance, and in what ways do these national initiatives align with the global frameworks and recommendations for responsible AI development?</td>\n",
       "      <td>Based on the provided context, the Philippines is developing a multi-year Philippine AI Roadmap to guide national and local efforts in harnessing AI, which will be reviewed at least every three years to adapt to rapidly evolving global AI and technological trends. The National AI Council (NAIC) is responsible for ensuring the progressive realization of this roadmap with clear targets. Additionally, the NAIC shall establish and maintain a National Registry of AI Systems.\\n\\nThe context also states that the NAIC is tasked to coordinate with international agencies and organizations with similar mandates and expertise in artificial intelligence. This coordination indicates the recognition of the importance of aligning national AI governance with international standards and practices.\\n\\nTherefore, the Philippines' multi-year AI Roadmap and the National Registry of AI Systems exemplify the importance of international coordination by committing to adapt to global AI trends, maintaining continuous review cycles, and explicitly mandating coordination with international AI bodies. These national efforts align with global frameworks and recommendations by focusing on a responsible, ethical, and adaptive approach to AI development, ensuring that AI use is safe and respects rights, while supporting innovation.\\n\\nIn summary:\\n- The Philippine AI Roadmap’s periodic review reflects responsiveness to global technological evolution and best practices.\\n- The National Registry supports transparency and monitoring, which is consistent with international recommendations on AI governance.\\n- Explicit coordination with international agencies demonstrates alignment with global frameworks emphasizing cooperation and harmonization in AI regulation.\\n\\nHence, these initiatives embody the global call for responsible AI development through adaptive, transparent, and cooperative governance structures.</td>\n",
       "      <td>None</td>\n",
       "      <td>The Philippines' development of a multi-year AI Roadmap and the establishment of a National Registry of AI Systems demonstrate a proactive approach to national AI governance that aligns with international efforts emphasizing coordination and responsible development. The Roadmap guides national and local efforts in harnessing AI, with regular reviews to adapt to evolving global trends, while the Registry ensures that all AI systems deployed within the country comply with regulatory and ethical standards. These initiatives reflect the themes of international coordination on AI governance by embodying principles such as transparency, accountability, and ethical oversight, which are also emphasized in global frameworks like the European Union's AI Act and the United Nations' recommendations. By integrating these national strategies with international standards, the Philippines contributes to a cohesive global effort to promote safe, responsible, and inclusive AI innovation.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.277950</td>\n",
       "      <td>bf554a99-e66b-46ea-9ffa-11908753c9ab</td>\n",
       "      <td>26c7a6eb-1337-4014-aa76-2bb310f14e10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is ASI and why is it like a big deal for AI research and development and what are the risks and concerns about it?</td>\n",
       "      <td>Based on the provided context:\\n\\nASI, or Artificial Superintelligence, refers to hypothetical AI systems that surpass human intelligence and potentially operate beyond human control. It is a big deal for AI research and development because ASI represents a level of intelligence greater than humans, which could greatly accelerate technological progress but also poses significant risks.\\n\\nThe risks and concerns about ASI include fears that if such systems are improperly secured or regulated, they might gain unauthorized access to critical infrastructure, including military assets like nuclear weapons, posing existential threats to humanity. There are also broader worries about the loss of meaningful human oversight, making ASI potentially uncontrollable and dangerous.\\n\\nIn summary, ASI is a highly advanced form of AI that offers enormous potential but comes with substantial risks, such as security threats, ethical challenges, and the possibility of surpassing human control.\\n\\n</td>\n",
       "      <td>None</td>\n",
       "      <td>The context mentions that the global scientific and policy communities have raised alarms regarding the possible rise of Artificial Superintelligence (ASI), which is a hypothetical AI system surpassing human intelligence and potentially beyond human control. The risks include concerns that such systems, if improperly secured or regulated, might gain unauthorized access to critical infrastructure, including military assets such as nuclear weapons, posing existential threats to humanity.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.569186</td>\n",
       "      <td>afcf509f-2a9e-4050-9aab-74849f1bc2ea</td>\n",
       "      <td>2cccc12a-7b07-4003-9e65-9e188eb1c380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the significance of the REPUBLIC OF THE PHILIPPINES in the context of AI regulation and development?</td>\n",
       "      <td>The significance of the Republic of the Philippines in the context of AI regulation and development is that it is the nation undertaking the establishment of a national framework to regulate the development and use of Artificial Intelligence (AI) systems. This framework aims to ensure the safe, responsible, ethical, and sustainable use of AI aligned with the country's vision of an inclusive, innovative, and secure digital future. The Philippine government, represented by its Congress and Senate, is actively working on legislation to promote ethical and responsible AI innovation, integrate sustainability and foresight in policymaking, and protect the rights and welfare of its citizens by preventing misuse or harm caused by AI technologies.</td>\n",
       "      <td>None</td>\n",
       "      <td>The context discusses the TWENTIETH CONGRESS OF THE REPLBLIC OF THE PHILIPPINES, which introduced an act regulating the development and use of artificial intelligence systems in the Philippines, promoting ethical and responsible AI innovation, and integrating sustainability and futures thinking in national policy making. It emphasizes the need for a national framework to ensure the safe, responsible, and ethical use of AI, aligned with global efforts and international legal frameworks.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.311119</td>\n",
       "      <td>9fa43029-97f0-4a2d-88b7-2b5e938eccda</td>\n",
       "      <td>bcf663ed-9bd8-4f45-8173-a096172702a0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults whispered-lettuce-34>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    rag_chain.invoke,\n",
    "    data=dataset_name,\n",
    "    evaluators=[\n",
    "        qa_evaluator,\n",
    "        labeled_helpfulness_evaluator,\n",
    "        empathy_evaluator\n",
    "    ],\n",
    "    metadata={\"revision_id\": \"default_chain_init\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI(model=\"gpt-4.1-nano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BM25 Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "bm25_retriever = BM25Retriever.from_documents(rag_documents)\n",
    "bm25_retriever.k = 10   # same effect as search_kwargs={\"k\": 10}\n",
    "\n",
    "bm25_retrieval_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | rag_prompt | llm | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'proper-weather-9' at:\n",
      "https://smith.langchain.com/o/73c7812f-fb16-4468-bb8f-115ba901532a/datasets/21fd1cce-754b-4695-81f3-4f8aefa58a02/compare?selectedSessions=351981c8-5401-45ac-b0ab-7c6ef43fbdaf\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a27319eeda99423998f1e81d7d8976ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.answer</th>\n",
       "      <th>feedback.correctness</th>\n",
       "      <th>feedback.helpfulness</th>\n",
       "      <th>feedback.empathy</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does the DOST relate to the NAIC's jurisdiction over AI development and regulation?</td>\n",
       "      <td>Based on the provided context, the DOST (Department of Science and Technology) is connected to the NAIC (presumably the National AI Commission) in several ways related to AI development and regulation:\\n\\n- The NAIC has original and exclusive jurisdiction over all matters pertaining to AI, including its development, promotion, registration, and regulation (Sec. 6).\\n- The NAIC includes, among its members, the Secretary of the DOST as Chairman (Sec. 7).\\n- The NAIC is responsible for technical support and policy alignment of all government offices involved in AI development, including those under or attached to the DOST and other concerned agencies (Sec. 6).\\n- The NAIC has the authority to impose administrative penalties for violations of the Act (Sec. 6).\\n  \\nTherefore, the DOST has a leadership role within the NAIC (its Secretary being the Chairman) and works closely through the NAIC to align policies and provide technical support for AI development and regulation across government offices, including those attached to the DOST.\\n\\n# Final answer\\n\\nThe DOST is integrally involved in the NAIC’s jurisdiction over AI as its Secretary serves as the NAIC Chairman, and the NAIC aligns technical support and policies across government offices, including those under or attached to the DOST, thus ensuring DOST’s leadership and active role in AI development and regulation.</td>\n",
       "      <td>None</td>\n",
       "      <td>The NAIC, which is attached to the Department of Science and Technology (DOST), has exclusive jurisdiction over all matters pertaining to AI, including its development, promotion, registration, and regulation. The NAIC is responsible for technical support and policy alignment across government agencies involved in AI, and it can impose administrative penalties for violations, establishing a direct relationship between DOST and the NAIC's AI oversight functions.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.325980</td>\n",
       "      <td>5b0bdfed-5b90-4119-82a9-a30f2ac69a3f</td>\n",
       "      <td>3a3e8df3-e175-46df-99f4-c94b1b915e82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does the development of Artificial Superintelligence (ASI) in the Philippines, as discussed in the context, relate to the global concerns about ASI surpassing human control and the need for responsible regulation to ensure safety and ethical use?</td>\n",
       "      <td>The context provided indicates that global scientific and policy communities have raised alarms regarding the possible rise of Artificial Superintelligence (ASI), which refers to hypothetical AI systems surpassing human intelligence and potentially going beyond human control. This risk includes fears that such systems, if improperly secured or regulated, might gain unchecked power.\\n\\nIn the Philippines, the development of AI, including concerns about ASI, is acknowledged within efforts to establish a clear legal and regulatory framework aimed at protecting the rights of Filipinos and promoting responsible AI adoption and innovation. The measures discussed emphasize the importance of effective regulation, programmatic direction, balancing regulation with consumer protection, and utilizing approaches like regulatory sandboxes to foster innovation while managing risks.\\n\\nTherefore, the development of ASI in the Philippines aligns with global concerns by recognizing the potential risks of ASI surpassing human control and underscores the necessity for responsible regulation to ensure safety, ethical use, and to address social inequities. The Philippines aims to address these challenges through legal and regulatory frameworks modeled to promote transparency, accountability, ethics, and consumer protection in AI deployment.\\n\\nIn summary, the Philippine approach reflects global concerns about ASI by emphasizing responsible regulation and safeguards to ensure ASI development is controlled, ethical, and beneficial to society.</td>\n",
       "      <td>None</td>\n",
       "      <td>The context highlights that AI presents significant opportunities for the Philippines, including improving public services and advancing technological development. However, it also raises concerns about the rise of Artificial Superintelligence (ASI), a hypothetical AI system surpassing human intelligence and potentially beyond human control. Globally, scientific and policy communities have expressed alarms regarding the risks of ASI gaining unauthorized access to critical infrastructure and posing existential threats. The Philippines' approach, as outlined, emphasizes responsible development and regulation of AI, including ASI, to balance innovation with safety, ethics, and human oversight. This aligns with international concerns by advocating for policies that ensure ASI remains secure, transparent, and under meaningful human control to prevent misuse or unintended consequences.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.665950</td>\n",
       "      <td>cec2f7f8-bf02-482c-b1d6-484da9ee5a5f</td>\n",
       "      <td>f02df715-a503-4e14-9619-733184be11c3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how do they do certification and monitoring of AI risks like in the law, and how does that relate to certification, and what does it mean for AI safety and risks, and how is it done in the law, and what are the rules for certifying AI risks, and how does that help with AI safety and risks, and what are the rules for certifying AI risks in the law, and how do they do it, and what are the rules for certifying AI risks, and how does that help AI safety and risks, and what does certification mean for AI risks and safety?</td>\n",
       "      <td>Based on the provided context from the documents, the certification and monitoring of AI risks as outlined in the law involve the following key points:\\n\\n1. **Pre-deployment Testing, Risk Identification, and Mitigation:**  \\n   AI systems must undergo thorough pre-deployment testing to identify potential risks and ensure the system is safe and effective based on its intended use. This includes mitigating unsafe outcomes, including those beyond the intended use, and ensuring adherence to domain-specific standards.\\n\\n2. **Ongoing Monitoring:**  \\n   After deployment, AI systems are subject to ongoing monitoring to continually assess safety and effectiveness, manage emerging risks, and ensure compliance with applicable standards.\\n\\n3. **Role of Automation Auditors:**  \\n   The law empowers the appointment of automation auditors who have the authority to probe and review the behavior of AI algorithms. This includes the power to inspect AI companies' premises (except for trade secrets and proprietary information as defined by the law’s implementing rules) and to require submission of written or electronic reports as necessary.\\n\\n4. **Certification as Part of a Robust Auditing Ecosystem:**  \\n   Certification is part of a robust auditing and certification ecosystem aimed at holding AI systems accountable for any harm caused. This involves establishing liability and ensuring technical AI safety research is supported.\\n\\n5. **Goals of Certification and Monitoring:**  \\n   The certification and monitoring rules serve to ensure that AI systems are developed and deployed responsibly, safeguarding against crime, harm, and social injustice. Certification validates that the AI system meets safety and ethical standards, thus helping reduce risks associated with AI applications.\\n\\n6. **Compliance with Domain-Specific Standards:**  \\n   AI systems must adhere to standards specific to their domain to ensure that safety risks particular to certain fields are adequately addressed in the certification process.\\n\\n**Summary:**  \\nIn the law, AI risk certification and monitoring entail a systematic process of testing, risk assessment, mitigation, continuous oversight, and auditor involvement to ensure safety and ethical compliance. Certification confirms that AI systems meet established safety and domain standards, contributing to the mitigation of AI-related risks and promoting safe and responsible AI deployment. This framework helps prevent unsafe outcomes, assigns liability for harm, and fosters trust in AI technologies.</td>\n",
       "      <td>None</td>\n",
       "      <td>The law states that the NAIC shall certify and monitor AI-related risks of all AI applications, which means they will evaluate and oversee AI systems to ensure safety and compliance. This certification process is part of a risk-based regulatory framework that classifies AI systems as high, moderate, or low risk based on their potential impact. By implementing certification and monitoring, the law aims to promote AI safety and manage risks effectively, ensuring AI systems align with ethical standards and social goals.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.160123</td>\n",
       "      <td>70734b8d-8b74-48fb-87c2-36eb0e1e0cc4</td>\n",
       "      <td>bb64fd78-5107-4ef0-83a9-c4f60d3d92de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does the Philippines' development of a multi-year AI Roadmap and the establishment of a National Registry of AI Systems exemplify the importance of international coordination on AI governance, and in what ways do these national initiatives align with the global frameworks and recommendations for responsible AI development?</td>\n",
       "      <td>Based on the provided context, the Philippines is developing a multi-year Philippine AI Roadmap to guide national and local efforts in harnessing AI, with periodic reviews at least every three years to adapt to evolving global AI and technological trends. Additionally, the National AI Council (NAIC) is tasked with establishing and maintaining a National Registry of AI Systems.\\n\\nThese national initiatives exemplify the importance of international coordination on AI governance in the following ways:\\n\\n1. **Alignment with Global Trends and Standards:**  \\n   The AI Roadmap is designed to be adaptive to rapidly evolving global AI and technological trends, showing an awareness of the international context in which AI development occurs. This reflects the recognition that AI governance must be responsive to global innovations and challenges.\\n\\n2. **Institutional Mechanisms Reflecting Global Best Practices:**  \\n   The establishment of a National Registry of AI Systems mirrors global efforts—such as the EU’s AI Act—to maintain transparency and accountability over AI systems. Registries help facilitate oversight, risk assessment, and compliance with standards, which are key components of international AI governance frameworks.\\n\\n3. **Progressive Realization and Clear Targets:**  \\n   The roadmap aims for progressive realization with clear targets, indicating a structured and measurable approach to responsible AI development, akin to international calls for governance frameworks that emphasize accountability, transparency, and ethical standards.\\n\\nRegarding alignment with global frameworks and recommendations:\\n\\n- The context references the European Union’s AI Act of 2024 and the United Nations Secretary-General’s High-Level Advisory Body on AI, which emphasize risk-based classification, transparency, accountability, human oversight, rights-based, transparent, and inclusive AI development.\\n\\n- The Philippines’ initiatives reflect these principles by promoting ethical and sustainable AI use, maintaining registries for oversight, and periodically reviewing policies to keep pace with technological changes, all of which resonate with international governance themes of transparency, inclusivity, and adaptability.\\n\\nIn summary, the Philippines’ multi-year AI Roadmap and National Registry serve as national embodiments of internationally recognized priorities for responsible AI governance, demonstrating the country's commitment to aligning domestic policies with global standards and facilitating coordination that supports a secure, ethical, and transparent AI ecosystem.\\n\\n</td>\n",
       "      <td>None</td>\n",
       "      <td>The Philippines' development of a multi-year AI Roadmap and the establishment of a National Registry of AI Systems demonstrate a proactive approach to national AI governance that aligns with international efforts emphasizing coordination and responsible development. The Roadmap guides national and local efforts in harnessing AI, with regular reviews to adapt to evolving global trends, while the Registry ensures that all AI systems deployed within the country comply with regulatory and ethical standards. These initiatives reflect the themes of international coordination on AI governance by embodying principles such as transparency, accountability, and ethical oversight, which are also emphasized in global frameworks like the European Union's AI Act and the United Nations' recommendations. By integrating these national strategies with international standards, the Philippines contributes to a cohesive global effort to promote safe, responsible, and inclusive AI innovation.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.802436</td>\n",
       "      <td>bf554a99-e66b-46ea-9ffa-11908753c9ab</td>\n",
       "      <td>a1a5ef9f-e2bb-42b8-b386-3ab49b8bed2b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is ASI and why is it like a big deal for AI research and development and what are the risks and concerns about it?</td>\n",
       "      <td>Based on the provided context, ASI (Artificial Superintelligence) is referenced implicitly as \"AI systems with human-competitive intelligence\" or \"Advanced AI\" that could represent a profound change in the history of life on Earth. It is described as systems more powerful than GPT-4 and is associated with potentially profound risks to society and humanity.\\n\\nThe significance of ASI for AI research and development lies in its profound transformative potential and the need for careful planning and management, as indicated by references to the Asilomar AI Principles which emphasize the importance of managing advanced AI safely.\\n\\nThe risks and concerns about ASI mentioned in the context include:\\n\\n- Profound risks to society and humanity due to the capabilities of such AI systems.\\n- Potential for oppression and danger to the information ecosystem.\\n- Concentration of power in the hands of a few, exacerbating social inequities.\\n- The need for transparency, documentation of training data and model architectures, and safety mechanisms to prevent misuse.\\n- The necessity to pause or heavily regulate development of AI systems more powerful than current top models to avoid unsafe outcomes.\\n\\nIn summary, ASI is considered a big deal because it represents a major technological milestone with transformative potential but also substantial societal risks that require robust regulation, transparency, and safeguards in AI research and development.</td>\n",
       "      <td>None</td>\n",
       "      <td>The context mentions that the global scientific and policy communities have raised alarms regarding the possible rise of Artificial Superintelligence (ASI), which is a hypothetical AI system surpassing human intelligence and potentially beyond human control. The risks include concerns that such systems, if improperly secured or regulated, might gain unauthorized access to critical infrastructure, including military assets such as nuclear weapons, posing existential threats to humanity.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.624396</td>\n",
       "      <td>afcf509f-2a9e-4050-9aab-74849f1bc2ea</td>\n",
       "      <td>f5bb0edd-9c75-4c5c-af78-0193a5b6bcc4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the significance of the REPUBLIC OF THE PHILIPPINES in the context of AI regulation and development?</td>\n",
       "      <td>Based on the provided context, the significance of the Republic of the Philippines in the context of AI regulation and development is that it is the governing nation enacting laws and measures to regulate the development and use of artificial intelligence systems within its jurisdiction. The documents show that the Philippine Congress and Senate are actively introducing and deliberating bills aimed at establishing legal and regulatory frameworks to promote ethical and responsible AI innovation, protect the rights of Filipinos, ensure transparency, and foster the responsible adoption of AI. These legislative efforts underline the country’s commitment to addressing the social, ethical, and economic impacts of AI through national policy making and regulation.</td>\n",
       "      <td>None</td>\n",
       "      <td>The context discusses the TWENTIETH CONGRESS OF THE REPLBLIC OF THE PHILIPPINES, which introduced an act regulating the development and use of artificial intelligence systems in the Philippines, promoting ethical and responsible AI innovation, and integrating sustainability and futures thinking in national policy making. It emphasizes the need for a national framework to ensure the safe, responsible, and ethical use of AI, aligned with global efforts and international legal frameworks.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.953907</td>\n",
       "      <td>9fa43029-97f0-4a2d-88b7-2b5e938eccda</td>\n",
       "      <td>da321da5-e4e4-4463-bb36-f4c7cd647a8d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults proper-weather-9>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    bm25_retrieval_chain.invoke,\n",
    "    data=dataset_name,\n",
    "    evaluators=[\n",
    "        qa_evaluator,\n",
    "        labeled_helpfulness_evaluator,\n",
    "        empathy_evaluator\n",
    "    ],\n",
    "    metadata={\"revision_id\": \"chain_init_bm25\"},\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi Query Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=retriever, llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_query_retrieval_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | rag_prompt | llm | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'vacant-match-22' at:\n",
      "https://smith.langchain.com/o/73c7812f-fb16-4468-bb8f-115ba901532a/datasets/21fd1cce-754b-4695-81f3-4f8aefa58a02/compare?selectedSessions=fe1ab4d6-b0ad-4dbc-8d37-e137c910f12f\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a828e411778a4121962d035b3036d693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.answer</th>\n",
       "      <th>feedback.correctness</th>\n",
       "      <th>feedback.helpfulness</th>\n",
       "      <th>feedback.empathy</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does the DOST relate to the NAIC's jurisdiction over AI development and regulation?</td>\n",
       "      <td>Based on the provided context, the National AI Commission (NAIC) is an agency attached to the Department of Science and Technology (DOST). The NAIC has original and exclusive jurisdiction over all matters pertaining to AI, including its development, promotion, registration, and regulation. Additionally, the Secretary of the DOST serves as the Chairman of the NAIC. Therefore, the DOST is directly connected to the NAIC's jurisdiction through its administrative attachment and leadership role, supporting and overseeing the NAIC's authority over AI development and regulation.</td>\n",
       "      <td>None</td>\n",
       "      <td>The NAIC, which is attached to the Department of Science and Technology (DOST), has exclusive jurisdiction over all matters pertaining to AI, including its development, promotion, registration, and regulation. The NAIC is responsible for technical support and policy alignment across government agencies involved in AI, and it can impose administrative penalties for violations, establishing a direct relationship between DOST and the NAIC's AI oversight functions.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.076947</td>\n",
       "      <td>5b0bdfed-5b90-4119-82a9-a30f2ac69a3f</td>\n",
       "      <td>f3e697ee-308c-427b-be26-53c6e2bacfb7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does the development of Artificial Superintelligence (ASI) in the Philippines, as discussed in the context, relate to the global concerns about ASI surpassing human control and the need for responsible regulation to ensure safety and ethical use?</td>\n",
       "      <td>The development of Artificial Superintelligence (ASI) in the Philippines is recognized within the context of global concerns that such AI systems could surpass human intelligence and potentially go beyond human control. This risk includes fears that improperly secured or regulated ASI might gain harmful autonomy. In response, the context highlights the urgent need for a national framework in the Philippines to ensure the safe, responsible, and ethical use of AI. This framework aims to protect the rights and welfare of citizens, prevent AI from perpetrating crimes or causing harm (whether intentional or accidental), and support technological progress in a responsible manner. Thus, the development of ASI in the Philippines is closely tied to these global concerns, emphasizing the necessity for strong regulation and oversight to manage AI risks and align AI advancements with national safety and ethical standards.</td>\n",
       "      <td>None</td>\n",
       "      <td>The context highlights that AI presents significant opportunities for the Philippines, including improving public services and advancing technological development. However, it also raises concerns about the rise of Artificial Superintelligence (ASI), a hypothetical AI system surpassing human intelligence and potentially beyond human control. Globally, scientific and policy communities have expressed alarms regarding the risks of ASI gaining unauthorized access to critical infrastructure and posing existential threats. The Philippines' approach, as outlined, emphasizes responsible development and regulation of AI, including ASI, to balance innovation with safety, ethics, and human oversight. This aligns with international concerns by advocating for policies that ensure ASI remains secure, transparent, and under meaningful human control to prevent misuse or unintended consequences.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.231049</td>\n",
       "      <td>cec2f7f8-bf02-482c-b1d6-484da9ee5a5f</td>\n",
       "      <td>35b44c3a-d828-47af-80cf-788b6efd5dce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how do they do certification and monitoring of AI risks like in the law, and how does that relate to certification, and what does it mean for AI safety and risks, and how is it done in the law, and what are the rules for certifying AI risks, and how does that help with AI safety and risks, and what are the rules for certifying AI risks in the law, and how do they do it, and what are the rules for certifying AI risks, and how does that help AI safety and risks, and what does certification mean for AI risks and safety?</td>\n",
       "      <td>Based on the provided context from the law:\\n\\n1. **Certification and Monitoring of AI Risks:**\\n   - AI systems classified as **high-risk** must undergo **mandatory algorithmic impact assessments, data privacy reviews, and sustainability screening** before being certified for use.\\n   - The **NAIC (presumably the designated regulatory body)** is responsible for classifying AI systems based on risk (high-risk, moderate-risk, low-risk) and certifying and monitoring AI-related risks of all AI applications.\\n   - The **AI Ethics Review Board** created by NAIC issues implementing guidelines, including risk thresholds, audit mechanisms, and sanctions for non-compliance.\\n\\n2. **Rules for Certifying AI Risks:**\\n   - Certification requires compliance with standards for **AI safety, transparency, accountability, explainability, and ethical compliance**, including safeguards against discrimination, misuse, harm, or unintended consequences.\\n   - There must be a **mechanism for redress or reporting adverse incidents** arising from AI use.\\n   - Providers must **take full responsibility for harms or unlawful outcomes** from their AI systems.\\n   - There must be a **clear mechanism to immediately halt, shut down, or disable** AI systems behaving unpredictably, exceeding intended functions, causing harm, or committing illegal acts.\\n\\n3. **Relation to AI Safety and Risks:**\\n   - Certification acts as a gatekeeper to ensure only AI systems meeting rigorous safety, ethical, and transparency standards are allowed for use.\\n   - Mandatory impact assessments and reviews help identify and mitigate risks before deployment.\\n   - Ongoing monitoring and the ability to disable problematic systems ensure continued safety and control.\\n   - These requirements help prevent harm, discrimination, misuse, and other adverse outcomes related to AI.\\n\\nIn summary, certification and monitoring under the law involve a risk-based classification system, mandatory assessments for high-risk AI, compliance with comprehensive safety and ethical standards, and mechanisms for enforcement and incident management. This process ensures AI systems are safe, accountable, and controlled to minimize risks.</td>\n",
       "      <td>None</td>\n",
       "      <td>The law states that the NAIC shall certify and monitor AI-related risks of all AI applications, which means they will evaluate and oversee AI systems to ensure safety and compliance. This certification process is part of a risk-based regulatory framework that classifies AI systems as high, moderate, or low risk based on their potential impact. By implementing certification and monitoring, the law aims to promote AI safety and manage risks effectively, ensuring AI systems align with ethical standards and social goals.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.992879</td>\n",
       "      <td>70734b8d-8b74-48fb-87c2-36eb0e1e0cc4</td>\n",
       "      <td>38fe9019-ffc5-48e2-bcf9-eae8de2b5e15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does the Philippines' development of a multi-year AI Roadmap and the establishment of a National Registry of AI Systems exemplify the importance of international coordination on AI governance, and in what ways do these national initiatives align with the global frameworks and recommendations for responsible AI development?</td>\n",
       "      <td>Based on the provided context, the Philippines is developing a multi-year AI Roadmap to guide national and local efforts in harnessing AI, which is to be reviewed at least every three years to adapt to rapidly evolving global AI and technological trends. Additionally, the National AI Council (NAIC) is tasked with establishing and maintaining a National Registry of AI Systems. The NAIC is also mandated to coordinate with international agencies and organizations with similar mandates and expertise in artificial intelligence.\\n\\nThese initiatives exemplify the importance of international coordination on AI governance by explicitly recognizing the need to align national strategies with global developments. The regular review of the AI Roadmap to adapt to evolving global trends highlights responsiveness to international innovations and standards. Coordination with international entities ensures that the Philippines’ efforts are informed by—and contribute to—global best practices, fostering harmonization and cooperation in AI governance.\\n\\nFurthermore, by integrating risk-based regulatory frameworks, classification of AI systems based on their risks, and certification and monitoring of AI-related risks, the national initiatives align with global frameworks that emphasize responsible, ethical, and safe AI development. Supporting Filipino-developed AI technologies through public-private partnerships also aligns with global recommendations to promote innovation while managing risks.\\n\\nIn sum, the Philippines’ development of the AI Roadmap and the National Registry, combined with mandated international coordination, demonstrates a commitment to responsible AI governance consistent with global standards and recommendations for ethical, safe, and innovative AI development.</td>\n",
       "      <td>None</td>\n",
       "      <td>The Philippines' development of a multi-year AI Roadmap and the establishment of a National Registry of AI Systems demonstrate a proactive approach to national AI governance that aligns with international efforts emphasizing coordination and responsible development. The Roadmap guides national and local efforts in harnessing AI, with regular reviews to adapt to evolving global trends, while the Registry ensures that all AI systems deployed within the country comply with regulatory and ethical standards. These initiatives reflect the themes of international coordination on AI governance by embodying principles such as transparency, accountability, and ethical oversight, which are also emphasized in global frameworks like the European Union's AI Act and the United Nations' recommendations. By integrating these national strategies with international standards, the Philippines contributes to a cohesive global effort to promote safe, responsible, and inclusive AI innovation.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.029286</td>\n",
       "      <td>bf554a99-e66b-46ea-9ffa-11908753c9ab</td>\n",
       "      <td>2bbe769e-3fec-4962-b2aa-0dc27b884099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is ASI and why is it like a big deal for AI research and development and what are the risks and concerns about it?</td>\n",
       "      <td>Based on the provided context:\\n\\n**ASI (Artificial Superintelligence)** refers to hypothetical AI systems that surpass human intelligence in all respects, including creativity, decision-making, and social intelligence.\\n\\nIt is a big deal for AI research and development because such systems could operate beyond human capabilities and potentially beyond human control. The global scientific and policy communities have raised alarms about the possible rise of ASI due to its profound implications.\\n\\nThe risks and concerns about ASI include:\\n\\n- The possibility that ASI systems, if improperly secured or regulated, might gain unauthorized access to critical infrastructure, including military assets such as nuclear weapons.\\n- Such unauthorized access or control poses existential threats to humanity.\\n- There are fears that ASI might surpass human oversight and control, leading to unpredictable and potentially catastrophic outcomes.\\n\\nThus, ASI presents both enormous opportunities and significant risks, making its regulation and oversight critical in AI development.</td>\n",
       "      <td>None</td>\n",
       "      <td>The context mentions that the global scientific and policy communities have raised alarms regarding the possible rise of Artificial Superintelligence (ASI), which is a hypothetical AI system surpassing human intelligence and potentially beyond human control. The risks include concerns that such systems, if improperly secured or regulated, might gain unauthorized access to critical infrastructure, including military assets such as nuclear weapons, posing existential threats to humanity.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.129899</td>\n",
       "      <td>afcf509f-2a9e-4050-9aab-74849f1bc2ea</td>\n",
       "      <td>cf101c0d-2697-4c24-8432-04a1428592a4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the significance of the REPUBLIC OF THE PHILIPPINES in the context of AI regulation and development?</td>\n",
       "      <td>Based on the provided context, the significance of the Republic of the Philippines in the context of AI regulation and development is that it is actively working to establish a national framework to ensure the safe, responsible, and ethical use of Artificial Intelligence (AI). The country aims to promote innovation and technological advancement while upholding the privacy, rights, safety, and dignity of its citizens. The Philippine government recognizes AI's potential to enhance productivity, improve public service delivery, boost economic competitiveness, and advance scientific, educational, and technological development. Moreover, the State bears the responsibility to ensure AI is not used to perpetrate crimes, abuse rights, or cause harm, supporting Filipino ingenuity and sustainable progress. The Philippines seeks to integrate sustainability and futures thinking into national policymaking regarding AI.</td>\n",
       "      <td>None</td>\n",
       "      <td>The context discusses the TWENTIETH CONGRESS OF THE REPLBLIC OF THE PHILIPPINES, which introduced an act regulating the development and use of artificial intelligence systems in the Philippines, promoting ethical and responsible AI innovation, and integrating sustainability and futures thinking in national policy making. It emphasizes the need for a national framework to ensure the safe, responsible, and ethical use of AI, aligned with global efforts and international legal frameworks.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.438907</td>\n",
       "      <td>9fa43029-97f0-4a2d-88b7-2b5e938eccda</td>\n",
       "      <td>e66e392c-d78d-4ae1-beee-62d8e3e8f41f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults vacant-match-22>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    multi_query_retrieval_chain.invoke,\n",
    "    data=dataset_name,\n",
    "    evaluators=[\n",
    "        qa_evaluator,\n",
    "        labeled_helpfulness_evaluator,\n",
    "        empathy_evaluator\n",
    "    ],\n",
    "    metadata={\"revision_id\": \"chain_init_multi_query\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parent Document Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "parent_docs = rag_documents\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "\n",
    "client = QdrantClient(location=\":memory:\")\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=\"full_documents\",\n",
    "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
    ")\n",
    "\n",
    "parent_document_vectorstore = QdrantVectorStore(\n",
    "    collection_name=\"full_documents\", embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"), client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = InMemoryStore()\n",
    "\n",
    "parent_document_retriever = ParentDocumentRetriever(\n",
    "    vectorstore = parent_document_vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_document_retriever.add_documents(parent_docs, ids=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_document_retrieval_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | rag_prompt | llm | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'notable-seat-51' at:\n",
      "https://smith.langchain.com/o/73c7812f-fb16-4468-bb8f-115ba901532a/datasets/21fd1cce-754b-4695-81f3-4f8aefa58a02/compare?selectedSessions=33ee55fe-4105-40b9-8c9d-ede67fe769b9\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f2a0b144724d19a8f69d4f7e95071b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.answer</th>\n",
       "      <th>feedback.correctness</th>\n",
       "      <th>feedback.helpfulness</th>\n",
       "      <th>feedback.empathy</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does the DOST relate to the NAIC's jurisdiction over AI development and regulation?</td>\n",
       "      <td>Based on the context, the DOST is directly involved in the NAIC's jurisdiction over AI development and regulation. The NAIC, which has original and exclusive jurisdiction over all matters pertaining to AI—including its development, promotion, registration, and regulation—includes the Secretary of the DOST as its Chairman. Additionally, the NAIC is responsible for technical support and policy alignment related to AI, involving government offices under or attached to the DOST and other concerned agencies involved in AI development. Therefore, the DOST plays a leading role within the NAIC in overseeing and supporting AI regulation and development activities.</td>\n",
       "      <td>None</td>\n",
       "      <td>The NAIC, which is attached to the Department of Science and Technology (DOST), has exclusive jurisdiction over all matters pertaining to AI, including its development, promotion, registration, and regulation. The NAIC is responsible for technical support and policy alignment across government agencies involved in AI, and it can impose administrative penalties for violations, establishing a direct relationship between DOST and the NAIC's AI oversight functions.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.318922</td>\n",
       "      <td>5b0bdfed-5b90-4119-82a9-a30f2ac69a3f</td>\n",
       "      <td>aee372a1-3e5a-4910-84f4-88ada6f6d8b1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does the development of Artificial Superintelligence (ASI) in the Philippines, as discussed in the context, relate to the global concerns about ASI surpassing human control and the need for responsible regulation to ensure safety and ethical use?</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>None</td>\n",
       "      <td>The context highlights that AI presents significant opportunities for the Philippines, including improving public services and advancing technological development. However, it also raises concerns about the rise of Artificial Superintelligence (ASI), a hypothetical AI system surpassing human intelligence and potentially beyond human control. Globally, scientific and policy communities have expressed alarms regarding the risks of ASI gaining unauthorized access to critical infrastructure and posing existential threats. The Philippines' approach, as outlined, emphasizes responsible development and regulation of AI, including ASI, to balance innovation with safety, ethics, and human oversight. This aligns with international concerns by advocating for policies that ensure ASI remains secure, transparent, and under meaningful human control to prevent misuse or unintended consequences.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160848</td>\n",
       "      <td>cec2f7f8-bf02-482c-b1d6-484da9ee5a5f</td>\n",
       "      <td>10687101-850d-4184-92e2-9f5de7365574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how do they do certification and monitoring of AI risks like in the law, and how does that relate to certification, and what does it mean for AI safety and risks, and how is it done in the law, and what are the rules for certifying AI risks, and how does that help with AI safety and risks, and what are the rules for certifying AI risks in the law, and how do they do it, and what are the rules for certifying AI risks, and how does that help AI safety and risks, and what does certification mean for AI risks and safety?</td>\n",
       "      <td>Based on the provided context from the law:\\n\\n1. **Certification and Monitoring of AI Risks:**\\n   - AI systems classified as high-risk must undergo **mandatory algorithmic impact assessments, data privacy reviews, and sustainability screening** before they can be certified for use.\\n   - This certification process ensures that high-risk AI applications are thoroughly evaluated for potential harms and compliance with ethical and legal standards.\\n   \\n2. **Relation to AI Safety and Risks:**\\n   - By subjecting high-risk AI systems to these rigorous assessments and reviews before certification, the law aims to identify and mitigate risks proactively.\\n   - This process helps to minimize potential harm to individuals, organizations, or social systems, thereby enhancing AI safety.\\n   \\n3. **Rules for Certifying AI Risks:**\\n   - The law requires detailed risk thresholds and audit mechanisms to be established by the AI Ethics Review Board.\\n   - Certification is contingent upon successfully passing the risk assessments, privacy reviews, and sustainability checks.\\n   - The AI Ethics Review Board issues implementing guidelines, sanctions for non-compliance, and oversees the monitoring of AI applications.\\n   \\n4. **How the Certification Helps AI Safety and Risk Management:**\\n   - Certification establishes a standard of accountability and transparency.\\n   - It acts as a gatekeeping mechanism to ensure only AI systems that meet established safety, ethical, and privacy requirements are deployed.\\n   - Regular audits and sanctions discourage non-compliance, promoting ongoing risk management throughout the AI system’s lifecycle.\\n\\nIn summary, the law implements a structured certification process for high-risk AI that involves comprehensive assessments and oversight by the AI Ethics Review Board to promote AI safety, ethical compliance, and risk mitigation.</td>\n",
       "      <td>None</td>\n",
       "      <td>The law states that the NAIC shall certify and monitor AI-related risks of all AI applications, which means they will evaluate and oversee AI systems to ensure safety and compliance. This certification process is part of a risk-based regulatory framework that classifies AI systems as high, moderate, or low risk based on their potential impact. By implementing certification and monitoring, the law aims to promote AI safety and manage risks effectively, ensuring AI systems align with ethical standards and social goals.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.209631</td>\n",
       "      <td>70734b8d-8b74-48fb-87c2-36eb0e1e0cc4</td>\n",
       "      <td>9e0b4260-883e-4aeb-a4be-6407466b6a59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does the Philippines' development of a multi-year AI Roadmap and the establishment of a National Registry of AI Systems exemplify the importance of international coordination on AI governance, and in what ways do these national initiatives align with the global frameworks and recommendations for responsible AI development?</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>None</td>\n",
       "      <td>The Philippines' development of a multi-year AI Roadmap and the establishment of a National Registry of AI Systems demonstrate a proactive approach to national AI governance that aligns with international efforts emphasizing coordination and responsible development. The Roadmap guides national and local efforts in harnessing AI, with regular reviews to adapt to evolving global trends, while the Registry ensures that all AI systems deployed within the country comply with regulatory and ethical standards. These initiatives reflect the themes of international coordination on AI governance by embodying principles such as transparency, accountability, and ethical oversight, which are also emphasized in global frameworks like the European Union's AI Act and the United Nations' recommendations. By integrating these national strategies with international standards, the Philippines contributes to a cohesive global effort to promote safe, responsible, and inclusive AI innovation.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.301101</td>\n",
       "      <td>bf554a99-e66b-46ea-9ffa-11908753c9ab</td>\n",
       "      <td>ad40a5de-bdf1-45d8-a2ac-5f3178bea3df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is ASI and why is it like a big deal for AI research and development and what are the risks and concerns about it?</td>\n",
       "      <td>ASI stands for Artificial Superintelligence, which refers to hypothetical AI systems that surpass human intelligence and are potentially beyond human control. It is a big deal for AI research and development because such systems could operate at levels far exceeding human cognitive abilities. The risks and concerns about ASI include fears that, if improperly secured or regulated, these systems might gain control or act in ways that are unpredictable and potentially harmful. This raises alarms in the global scientific and policy communities regarding safety, control, and ethical issues associated with ASI.</td>\n",
       "      <td>None</td>\n",
       "      <td>The context mentions that the global scientific and policy communities have raised alarms regarding the possible rise of Artificial Superintelligence (ASI), which is a hypothetical AI system surpassing human intelligence and potentially beyond human control. The risks include concerns that such systems, if improperly secured or regulated, might gain unauthorized access to critical infrastructure, including military assets such as nuclear weapons, posing existential threats to humanity.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.219473</td>\n",
       "      <td>afcf509f-2a9e-4050-9aab-74849f1bc2ea</td>\n",
       "      <td>8a93c9a9-8393-45d7-8fdf-caaeb5d03c3e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the significance of the REPUBLIC OF THE PHILIPPINES in the context of AI regulation and development?</td>\n",
       "      <td>Based on the provided context, the significance of the Republic of the Philippines in the context of AI regulation and development is that it is undertaking legislative efforts to regulate the development and use of artificial intelligence systems within the country. This involves promoting ethical and responsible AI innovation and integrating sustainability and futures thinking into national policymaking to ensure a safe, inclusive, innovative, and secure digital future for the nation.</td>\n",
       "      <td>None</td>\n",
       "      <td>The context discusses the TWENTIETH CONGRESS OF THE REPLBLIC OF THE PHILIPPINES, which introduced an act regulating the development and use of artificial intelligence systems in the Philippines, promoting ethical and responsible AI innovation, and integrating sustainability and futures thinking in national policy making. It emphasizes the need for a national framework to ensure the safe, responsible, and ethical use of AI, aligned with global efforts and international legal frameworks.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.001440</td>\n",
       "      <td>9fa43029-97f0-4a2d-88b7-2b5e938eccda</td>\n",
       "      <td>3db507e5-2fcd-44b1-a94f-39b890f199f0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults notable-seat-51>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    parent_document_retrieval_chain.invoke,\n",
    "    data=dataset_name,\n",
    "    evaluators=[\n",
    "        qa_evaluator,\n",
    "        labeled_helpfulness_evaluator,\n",
    "        empathy_evaluator\n",
    "    ],\n",
    "    metadata={\"revision_id\": \"chain_init_parent_doc\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compression Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain_cohere import CohereRerank\n",
    "\n",
    "compressor = CohereRerank(model=\"rerank-v3.5\")\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextual_compression_retrieval_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | rag_prompt | llm | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'scholarly-society-6' at:\n",
      "https://smith.langchain.com/o/73c7812f-fb16-4468-bb8f-115ba901532a/datasets/21fd1cce-754b-4695-81f3-4f8aefa58a02/compare?selectedSessions=3ac99ac9-c611-4754-a24b-d525965fff43\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c2bbb99d12c4ea58e3950755918958d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.answer</th>\n",
       "      <th>feedback.correctness</th>\n",
       "      <th>feedback.helpfulness</th>\n",
       "      <th>feedback.empathy</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does the DOST relate to the NAIC's jurisdiction over AI development and regulation?</td>\n",
       "      <td>Based on the context, the NAIC (National AI Commission) is an agency attached to the Department of Science and Technology (DOST). The NAIC has the original and exclusive jurisdiction over all matters pertaining to AI, including its development, promotion, registration, and regulation. Therefore, the DOST relates to the NAIC by being the parent agency to which the NAIC is attached, while the NAIC holds the jurisdiction over AI matters.</td>\n",
       "      <td>None</td>\n",
       "      <td>The NAIC, which is attached to the Department of Science and Technology (DOST), has exclusive jurisdiction over all matters pertaining to AI, including its development, promotion, registration, and regulation. The NAIC is responsible for technical support and policy alignment across government agencies involved in AI, and it can impose administrative penalties for violations, establishing a direct relationship between DOST and the NAIC's AI oversight functions.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.611072</td>\n",
       "      <td>5b0bdfed-5b90-4119-82a9-a30f2ac69a3f</td>\n",
       "      <td>6a9fd6d9-590c-4c1a-8f58-6a8d9e1633c8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does the development of Artificial Superintelligence (ASI) in the Philippines, as discussed in the context, relate to the global concerns about ASI surpassing human control and the need for responsible regulation to ensure safety and ethical use?</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>None</td>\n",
       "      <td>The context highlights that AI presents significant opportunities for the Philippines, including improving public services and advancing technological development. However, it also raises concerns about the rise of Artificial Superintelligence (ASI), a hypothetical AI system surpassing human intelligence and potentially beyond human control. Globally, scientific and policy communities have expressed alarms regarding the risks of ASI gaining unauthorized access to critical infrastructure and posing existential threats. The Philippines' approach, as outlined, emphasizes responsible development and regulation of AI, including ASI, to balance innovation with safety, ethics, and human oversight. This aligns with international concerns by advocating for policies that ensure ASI remains secure, transparent, and under meaningful human control to prevent misuse or unintended consequences.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.438988</td>\n",
       "      <td>cec2f7f8-bf02-482c-b1d6-484da9ee5a5f</td>\n",
       "      <td>65e313e0-87a3-4c40-90bd-5d1472631724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how do they do certification and monitoring of AI risks like in the law, and how does that relate to certification, and what does it mean for AI safety and risks, and how is it done in the law, and what are the rules for certifying AI risks, and how does that help with AI safety and risks, and what are the rules for certifying AI risks in the law, and how do they do it, and what are the rules for certifying AI risks, and how does that help AI safety and risks, and what does certification mean for AI risks and safety?</td>\n",
       "      <td>Based on the provided context from the AI Regulation Act, certification and monitoring of AI risks are conducted through a risk-based regulatory framework that classifies AI systems into categories such as high-risk and moderate-risk based on their potential impact on safety, rights, and national interest.\\n\\nFor high-risk AI systems, the law mandates mandatory algorithmic impact assessments, data privacy reviews, and sustainability screening before these systems can be certified for use. This certification process ensures that AI systems meet certain safety and ethical standards before deployment, directly contributing to managing and mitigating AI-related risks.\\n\\nThe rules for certifying AI risks involve:\\n\\n- Classifying AI systems by risk level (high-risk, moderate-risk, low-risk) depending on their potential effects.\\n- Requiring high-risk AI systems to undergo comprehensive assessments (algorithmic impact, privacy, sustainability) prior to certification.\\n- Monitoring AI applications to ensure ongoing compliance and risk management.\\n\\nThis certification and monitoring framework helps enhance AI safety by ensuring that potentially harmful AI systems are thoroughly evaluated and regulated before and during their use. It aims to protect individuals, organizations, and societal interests by preventing unsafe or rights-compromising AI deployments.\\n\\nIn summary, certification in the law means that AI systems—especially those deemed high-risk—must pass specific assessments and reviews confirming their safety and compliance before being approved for use. This process is integral to reducing AI risks and safeguarding ethical and safety standards.</td>\n",
       "      <td>None</td>\n",
       "      <td>The law states that the NAIC shall certify and monitor AI-related risks of all AI applications, which means they will evaluate and oversee AI systems to ensure safety and compliance. This certification process is part of a risk-based regulatory framework that classifies AI systems as high, moderate, or low risk based on their potential impact. By implementing certification and monitoring, the law aims to promote AI safety and manage risks effectively, ensuring AI systems align with ethical standards and social goals.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.520985</td>\n",
       "      <td>70734b8d-8b74-48fb-87c2-36eb0e1e0cc4</td>\n",
       "      <td>ba0e5767-4595-4b61-a0e6-a6d2b95253d3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does the Philippines' development of a multi-year AI Roadmap and the establishment of a National Registry of AI Systems exemplify the importance of international coordination on AI governance, and in what ways do these national initiatives align with the global frameworks and recommendations for responsible AI development?</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>None</td>\n",
       "      <td>The Philippines' development of a multi-year AI Roadmap and the establishment of a National Registry of AI Systems demonstrate a proactive approach to national AI governance that aligns with international efforts emphasizing coordination and responsible development. The Roadmap guides national and local efforts in harnessing AI, with regular reviews to adapt to evolving global trends, while the Registry ensures that all AI systems deployed within the country comply with regulatory and ethical standards. These initiatives reflect the themes of international coordination on AI governance by embodying principles such as transparency, accountability, and ethical oversight, which are also emphasized in global frameworks like the European Union's AI Act and the United Nations' recommendations. By integrating these national strategies with international standards, the Philippines contributes to a cohesive global effort to promote safe, responsible, and inclusive AI innovation.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.360404</td>\n",
       "      <td>bf554a99-e66b-46ea-9ffa-11908753c9ab</td>\n",
       "      <td>24509a31-a1dd-431d-a12c-4133dc89f206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is ASI and why is it like a big deal for AI research and development and what are the risks and concerns about it?</td>\n",
       "      <td>Artificial Superintelligence (ASI) refers to hypothetical AI systems that surpass human intelligence and potentially are beyond human control. It is a big deal for AI research and development because such systems could have capabilities far exceeding those of humans, raising significant concerns. The risks and concerns about ASI include fears that if these systems are improperly secured or regulated, they might gain control in ways that could be harmful or uncontrollable, posing serious challenges to safety and governance.</td>\n",
       "      <td>None</td>\n",
       "      <td>The context mentions that the global scientific and policy communities have raised alarms regarding the possible rise of Artificial Superintelligence (ASI), which is a hypothetical AI system surpassing human intelligence and potentially beyond human control. The risks include concerns that such systems, if improperly secured or regulated, might gain unauthorized access to critical infrastructure, including military assets such as nuclear weapons, posing existential threats to humanity.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.005040</td>\n",
       "      <td>afcf509f-2a9e-4050-9aab-74849f1bc2ea</td>\n",
       "      <td>1ae0c793-ec22-4e96-90b4-71a234bf3688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the significance of the REPUBLIC OF THE PHILIPPINES in the context of AI regulation and development?</td>\n",
       "      <td>The significance of the Republic of the Philippines in the context of AI regulation and development is that it is the governing body under which the legislative act regulating the development and use of artificial intelligence systems is being proposed and enacted. The document reflects the Philippines' commitment to promoting ethical and responsible AI innovation, integrating sustainability and futures thinking into national policymaking, and ensuring that AI supports national development while protecting the rights and welfare of its citizens.</td>\n",
       "      <td>None</td>\n",
       "      <td>The context discusses the TWENTIETH CONGRESS OF THE REPLBLIC OF THE PHILIPPINES, which introduced an act regulating the development and use of artificial intelligence systems in the Philippines, promoting ethical and responsible AI innovation, and integrating sustainability and futures thinking in national policy making. It emphasizes the need for a national framework to ensure the safe, responsible, and ethical use of AI, aligned with global efforts and international legal frameworks.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.396019</td>\n",
       "      <td>9fa43029-97f0-4a2d-88b7-2b5e938eccda</td>\n",
       "      <td>c7017110-602f-4647-ba92-4345d1c3c31b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults scholarly-society-6>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    contextual_compression_retrieval_chain.invoke,\n",
    "    data=dataset_name,\n",
    "    evaluators=[\n",
    "        qa_evaluator,\n",
    "        labeled_helpfulness_evaluator,\n",
    "        empathy_evaluator\n",
    "    ],\n",
    "    metadata={\"revision_id\": \"chain_init_compression\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n",
    "semantic_chunker = SemanticChunker(\n",
    "    embeddings,\n",
    "    breakpoint_threshold_type=\"percentile\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_documents = semantic_chunker.split_documents(rag_documents[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_vectorstore = Qdrant.from_documents(\n",
    "    semantic_documents,\n",
    "    embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"AI_Bills_Data_Semantic_Chunks\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_retrieval_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | rag_prompt | llm | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'clear-fire-83' at:\n",
      "https://smith.langchain.com/o/73c7812f-fb16-4468-bb8f-115ba901532a/datasets/21fd1cce-754b-4695-81f3-4f8aefa58a02/compare?selectedSessions=7e17bc7d-b3d3-4e83-b5bc-28706a7e2341\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1853ba00774a4a9305ec21b42d378d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.answer</th>\n",
       "      <th>feedback.correctness</th>\n",
       "      <th>feedback.helpfulness</th>\n",
       "      <th>feedback.empathy</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does the DOST relate to the NAIC's jurisdiction over AI development and regulation?</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>None</td>\n",
       "      <td>The NAIC, which is attached to the Department of Science and Technology (DOST), has exclusive jurisdiction over all matters pertaining to AI, including its development, promotion, registration, and regulation. The NAIC is responsible for technical support and policy alignment across government agencies involved in AI, and it can impose administrative penalties for violations, establishing a direct relationship between DOST and the NAIC's AI oversight functions.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.305145</td>\n",
       "      <td>5b0bdfed-5b90-4119-82a9-a30f2ac69a3f</td>\n",
       "      <td>a0605be9-9a7a-49be-b869-bcc54c23a600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does the development of Artificial Superintelligence (ASI) in the Philippines, as discussed in the context, relate to the global concerns about ASI surpassing human control and the need for responsible regulation to ensure safety and ethical use?</td>\n",
       "      <td>The development of Artificial Superintelligence (ASI) in the Philippines, as discussed in the context, acknowledges the global concerns about ASI surpassing human intelligence and potentially going beyond human control. The context highlights that there are risks associated with improperly secured or regulated ASI systems, which could lead to harmful consequences. Therefore, the Act aims to regulate the development and use of all types of AI, including ASI, to ensure safety, ethical use, and to prevent crimes, rights abuses, and unintended harms. It emphasizes the State’s responsibility to promote responsible and lawful AI innovation while protecting citizens and supporting national development. This reflects a commitment to addressing the global alarms around ASI by integrating responsible regulation and safety measures in the Philippine national framework.</td>\n",
       "      <td>None</td>\n",
       "      <td>The context highlights that AI presents significant opportunities for the Philippines, including improving public services and advancing technological development. However, it also raises concerns about the rise of Artificial Superintelligence (ASI), a hypothetical AI system surpassing human intelligence and potentially beyond human control. Globally, scientific and policy communities have expressed alarms regarding the risks of ASI gaining unauthorized access to critical infrastructure and posing existential threats. The Philippines' approach, as outlined, emphasizes responsible development and regulation of AI, including ASI, to balance innovation with safety, ethics, and human oversight. This aligns with international concerns by advocating for policies that ensure ASI remains secure, transparent, and under meaningful human control to prevent misuse or unintended consequences.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.271500</td>\n",
       "      <td>cec2f7f8-bf02-482c-b1d6-484da9ee5a5f</td>\n",
       "      <td>45b56bfa-af73-4341-ab84-1b377acddc17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how do they do certification and monitoring of AI risks like in the law, and how does that relate to certification, and what does it mean for AI safety and risks, and how is it done in the law, and what are the rules for certifying AI risks, and how does that help with AI safety and risks, and what are the rules for certifying AI risks in the law, and how do they do it, and what are the rules for certifying AI risks, and how does that help AI safety and risks, and what does certification mean for AI risks and safety?</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>None</td>\n",
       "      <td>The law states that the NAIC shall certify and monitor AI-related risks of all AI applications, which means they will evaluate and oversee AI systems to ensure safety and compliance. This certification process is part of a risk-based regulatory framework that classifies AI systems as high, moderate, or low risk based on their potential impact. By implementing certification and monitoring, the law aims to promote AI safety and manage risks effectively, ensuring AI systems align with ethical standards and social goals.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.148682</td>\n",
       "      <td>70734b8d-8b74-48fb-87c2-36eb0e1e0cc4</td>\n",
       "      <td>75ed73ef-fab7-493f-ad9e-6e56e290c16a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does the Philippines' development of a multi-year AI Roadmap and the establishment of a National Registry of AI Systems exemplify the importance of international coordination on AI governance, and in what ways do these national initiatives align with the global frameworks and recommendations for responsible AI development?</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>None</td>\n",
       "      <td>The Philippines' development of a multi-year AI Roadmap and the establishment of a National Registry of AI Systems demonstrate a proactive approach to national AI governance that aligns with international efforts emphasizing coordination and responsible development. The Roadmap guides national and local efforts in harnessing AI, with regular reviews to adapt to evolving global trends, while the Registry ensures that all AI systems deployed within the country comply with regulatory and ethical standards. These initiatives reflect the themes of international coordination on AI governance by embodying principles such as transparency, accountability, and ethical oversight, which are also emphasized in global frameworks like the European Union's AI Act and the United Nations' recommendations. By integrating these national strategies with international standards, the Philippines contributes to a cohesive global effort to promote safe, responsible, and inclusive AI innovation.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.102904</td>\n",
       "      <td>bf554a99-e66b-46ea-9ffa-11908753c9ab</td>\n",
       "      <td>83268385-8d6c-4a4b-9272-22f125258e97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is ASI and why is it like a big deal for AI research and development and what are the risks and concerns about it?</td>\n",
       "      <td>Artificial Superintelligence (ASI) refers to hypothetical AI systems that surpass human intelligence and potentially go beyond human control. It is a big deal for AI research and development because such systems could have capabilities far exceeding current AI, posing significant challenges in ensuring they remain safe and under meaningful human oversight. The risks and concerns about ASI include the possibility that, if improperly secured or regulated, these systems might gain unauthorized access to critical infrastructure, including military assets such as nuclear weapons, thereby posing existential threats to humanity. Additionally, there are fears around AI hallucinations, bias, discrimination, and the generation of false or misleading outputs with confidence. Overall, ASI raises alarms globally about its potential impact on safety, ethics, transparency, and control in AI deployment.</td>\n",
       "      <td>None</td>\n",
       "      <td>The context mentions that the global scientific and policy communities have raised alarms regarding the possible rise of Artificial Superintelligence (ASI), which is a hypothetical AI system surpassing human intelligence and potentially beyond human control. The risks include concerns that such systems, if improperly secured or regulated, might gain unauthorized access to critical infrastructure, including military assets such as nuclear weapons, posing existential threats to humanity.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.215035</td>\n",
       "      <td>afcf509f-2a9e-4050-9aab-74849f1bc2ea</td>\n",
       "      <td>3af3c381-b9ed-4c66-b7b4-484f6c4b84ab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the significance of the REPUBLIC OF THE PHILIPPINES in the context of AI regulation and development?</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>None</td>\n",
       "      <td>The context discusses the TWENTIETH CONGRESS OF THE REPLBLIC OF THE PHILIPPINES, which introduced an act regulating the development and use of artificial intelligence systems in the Philippines, promoting ethical and responsible AI innovation, and integrating sustainability and futures thinking in national policy making. It emphasizes the need for a national framework to ensure the safe, responsible, and ethical use of AI, aligned with global efforts and international legal frameworks.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.476025</td>\n",
       "      <td>9fa43029-97f0-4a2d-88b7-2b5e938eccda</td>\n",
       "      <td>75dee281-a327-43c8-b386-a1fcf780436c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults clear-fire-83>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    semantic_retrieval_chain.invoke,\n",
    "    data=dataset_name,\n",
    "    evaluators=[\n",
    "        qa_evaluator,\n",
    "        labeled_helpfulness_evaluator,\n",
    "        empathy_evaluator\n",
    "    ],\n",
    "    metadata={\"revision_id\": \"chain_init_semantic_chunk\"},\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "13-advanced-retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
